{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.feature import local_binary_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current folder is: /home/ricardino/Documents/MAIA/tercer_semestre/CAD/Projecte/Machine_Learning/notebooks/features\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subfolder_path = Path.cwd()\n",
    "notebooks_path = subfolder_path.parent\n",
    "repo_path = notebooks_path.parent\n",
    "os.chdir(str(subfolder_path))\n",
    "#print current working directory\n",
    "print(f'Current folder is: {os.getcwd()}\\n')\n",
    "thispath = Path.cwd().resolve()\n",
    "import sys; sys.path.insert(0, str(thispath.parent.parent)) if sys.path[0] != str(thispath.parent.parent) else None\n",
    "\n",
    "#Import paths and patients classes\n",
    "from notebooks.info import path_label, patient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print 3 channel image given its numpy array\n",
    "def show_image_3channels(image):\n",
    "    \"\"\"Print 3 channel image given its numpy array\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "#functio to save file as pickle\n",
    "def save_as_pickle(file, filename):\n",
    "    \"\"\"Save file as pickle\n",
    "    \"\"\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(file, f, pickle.HIGHEST_PROTOCOL)\n",
    "def load_pickle(filename):\n",
    "    \"\"\"Load pickle file\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LBP_3channels(im_chs, neighbors=12, radius=2, method='uniform'):\n",
    "    \"\"\"Get LBP features from 3 channels\n",
    "\n",
    "    Args:\n",
    "        im_chs (3D array): 3 channels image\n",
    "        neighbors (int, optional): number of neighbors. Defaults to 12.\n",
    "        radius (int, optional): radious to extract. Defaults to 2.\n",
    "        method (str, optional): normally uniform is used but others are available. Defaults to 'uniform'.\n",
    "\n",
    "    Returns:\n",
    "        array: size 3*number of LBP features\n",
    "    \"\"\"\n",
    "    lbp = local_binary_pattern(im_chs[:,:,0], P=neighbors, R=radius, method=method)\n",
    "    lbp_count_1, _ = np.histogram(lbp, density = True, bins=10, range = (0, int(lbp.max())+1))\n",
    "    lbp = local_binary_pattern(im_chs[:,:,1], P=neighbors, R=radius, method=method)\n",
    "    lbp_count_2, _ = np.histogram(lbp, density = True, bins=10, range = (0, int(lbp.max())+1))\n",
    "    lbp = local_binary_pattern(im_chs[:,:,2], P=neighbors, R=radius, method=method)\n",
    "    lbp_count_3, _ = np.histogram(lbp, density = True, bins=10, range = (0, int(lbp.max())+1))\n",
    "    \n",
    "    return np.concatenate((lbp_count_1, lbp_count_2, lbp_count_3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6340/6340 [22:53<00:00,  4.62it/s]\n"
     ]
    }
   ],
   "source": [
    "#Read meta information\n",
    "classif = 'binary'\n",
    "NH_status = True #Hair removal yes or no\n",
    "fname = 'lbp_hsv'\n",
    "\n",
    "for set_name in ['test']:\n",
    "\n",
    "    #Get information for this case\n",
    "    info = path_label(classif = classif, set_name=set_name)\n",
    "\n",
    "    lbp_matrix = np.zeros((info.len, 30)) #define lbp matrix\n",
    "    for i in tqdm(range(info.len)):\n",
    "        pacient = patient(info=info, num=i, NH = NH_status)\n",
    "        lbp_matrix[i] = get_LBP_3channels(pacient.HSV_im(), neighbors=12, radius=2, method='uniform')\n",
    "\n",
    "    #save matrix as pickle\n",
    "    save_as_pickle(lbp_matrix, str(repo_path) + f'/data/features/texture/{classif}_{set_name}_{fname}_fv.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate all LBP features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif = 'binary'\n",
    "set_name = 'test'\n",
    "\n",
    "#Concatenate all 3 channels LBP features\n",
    "lbp_rgb = load_pickle(str(repo_path) + f'/data/features/texture/{classif}_{set_name}_lbp_rgb_fv.p')\n",
    "lbp_hsv = load_pickle(str(repo_path) + f'/data/features/texture/{classif}_{set_name}_lbp_hsv_fv.p')\n",
    "lbp_ycrcb = load_pickle(str(repo_path) + f'/data/features/texture/{classif}_{set_name}_lbp_ycrcb_fv.p')\n",
    "lbp_features = np.concatenate((lbp_rgb, lbp_hsv, lbp_ycrcb), axis=1)\n",
    "save_as_pickle(lbp_features, str(repo_path) + f'/data/features/texture/{classif}_{set_name}_lbp_NH_fv.p')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c1f01218bbaf8a302f18173488403fcc9591627716b9a07a59bd925307e4c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
